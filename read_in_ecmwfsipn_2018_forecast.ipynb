{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "##This code clears all the variables from the workspace; can help avoid memory errors\n",
    "def clear_all():\n",
    "    \"\"\"Clears all the variables from the workspace of the spyder application.\"\"\"\n",
    "    gl = globals().copy()\n",
    "    for var in gl:\n",
    "        if var[0] == '_': continue\n",
    "        if 'func' in str(globals()[var]): continue\n",
    "        if 'module' in str(globals()[var]): continue\n",
    "\n",
    "        del globals()[var]\n",
    "if __name__ == \"__main__\":\n",
    "    clear_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import forecast data (2017-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:       (ensemble: 51, fore_time: 215, init_time: 25, nregions: 15)\n",
      "Coordinates:\n",
      "  * fore_time     (fore_time) timedelta64[ns] 1 days 2 days ... 215 days\n",
      "  * ensemble      (ensemble) int32 0 1 2 3 4 5 6 7 8 ... 43 44 45 46 47 48 49 50\n",
      "  * nregions      (nregions) int64 99 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      "    region_names  (nregions) object 'panArctic' ... 'Central Arctic'\n",
      "  * init_time     (init_time) datetime64[ns] 2017-11-01 ... 2019-11-01\n",
      "Data variables:\n",
      "    Extent        (init_time, ensemble, fore_time, nregions) float64 dask.array<shape=(25, 51, 215, 15), chunksize=(1, 51, 215, 15)>\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ecmwfsipn'\n",
    "model_type = 'forecast'\n",
    "filepath = '/home/disk/sipn/nicway/data/model/{model_name}/{model_type}/sipn_nc_agg/'.format(model_name=model_name,\n",
    "                                              model_type=model_type)\n",
    "filenames = xr.open_mfdataset(filepath+'/*.nc',concat_dim='init_time')\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Kara-Laptev and E-Sib/Beauf/Chukchi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_names = filenames.region_names\n",
    "region_names = np.append(region_names,['Kara-Laptev','East-Siberian-Beaufort-Chukchi'])\n",
    "init_times = filenames.init_time\n",
    "forecast_times = filenames.fore_time\n",
    "extent = filenames.Extent\n",
    "##chunk sizes in dimensions of [init_time x ensemble x fore_time x region]\n",
    "chunk_sizes = filenames['Extent'].shape\n",
    "extent_KL = extent[:,:,:,8] + extent[:,:,:,9]\n",
    "extent_ESBC = extent[:,:,:,10] + extent[:,:,:,11] + extent[:,:,:,12]\n",
    "extent_extras= np.stack((extent_KL,extent_ESBC),axis=3)\n",
    "extent = np.concatenate((extent,extent_extras),axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll define VRILEs as the 5th percentile events of 5-day changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_ens = len(filenames.ensemble) ##no. of ensemble members\n",
    "no_day_change = 5 ##looking at 5 day changes\n",
    "no_forecast_periods = len(forecast_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize our output. Since SIE is a time series, we'll use Pandas and a DataFrame. For now, we will track initialization date, valid date, the actual SIE, lead time (in days, this will be a timedelta object), 5-day change in SIE (this will be recorded for the center day), ensemble number, and region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_SIC_ALL_ens = pd.DataFrame(columns=[\"I (init date)\",\n",
    "                                      \"V (valid date)\",\n",
    "                                      \"V_mon (valid date month)\",\n",
    "                                      \"V_yr (valid date year)\",\n",
    "                                      \"SIE\",\n",
    "                                      \"lead time (V - I)\",\n",
    "                                      \"d_SIE (V - I)\",\n",
    "                                      \"ensemble\",\n",
    "                                      \"region\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each region, then each forecast time and just calculcate d_SIE and add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panArctic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/mcmcgraw/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sea of Okhotsk\n",
      "Bering\n",
      "Hudson Bay\n",
      "St John\n",
      "Baffin Bay\n",
      "East Greenland Sea\n",
      "Barents Sea\n",
      "Kara Sea\n",
      "Laptev Sea\n",
      "East Siberian Sea\n",
      "Chukchi Sea\n",
      "Beaufort Sea\n",
      "Canadian Islands\n",
      "Central Arctic\n",
      "Kara-Laptev\n",
      "East-Siberian-Beaufort-Chukchi\n"
     ]
    }
   ],
   "source": [
    "##Create integers for each region\n",
    "##I could probably write this better with more uses of groupby. \n",
    "reg_sel = np.arange(0,17)\n",
    "##Outer loop will go through each region\n",
    "for ireg in reg_sel:\n",
    "    #ireg = 0\n",
    "    region_name = region_names[ireg]\n",
    "    region_select = ireg\n",
    "    print(region_name)\n",
    "    ##Next loop will go through each init time\n",
    "    for itime in np.arange(0,len(init_times)):\n",
    "    #itime = 0\n",
    "        init_times_df = pd.DatetimeIndex(init_times.values)\n",
    "        init_select = init_times_df[itime]#.to_dataset()\n",
    "        check_yr = pd.to_datetime(init_select).year\n",
    "        #if check_yr != 2018:\n",
    "            #print('not the right yr')\n",
    "            #continue\n",
    "        #print(init_select)\n",
    "\n",
    "        ##We'll create another DataFrame inside this loop; we'll append it \n",
    "        ##to the big DataFrame outside of this loop.\n",
    "        d_SIC_lead_time = pd.DataFrame({\"I (init date)\":pd.Series(init_select).repeat(len(forecast_times)*no_ens),\n",
    "                                    \"V (valid date)\":\"\",\n",
    "                                    \"V_mon (valid date month)\":\"\",\n",
    "                                    \"V_yr (valid date year)\":\"\",\n",
    "                                    \"SIE\":\"\",\n",
    "                                    \"lead time (days)\":\"\",\n",
    "                                    \"d_SIC (V - I)\":\"\",\n",
    "                                    \"ensemble\":\"\",\n",
    "                                    \"region\":\"\"})\n",
    "        ##Now, we loop through our ensemble members\n",
    "        for iens in np.arange(0,no_ens):\n",
    "            #iens = 0\n",
    "            ##Keep track of the correct indices so we don't have to append ad infitum\n",
    "            save_ind = iens*(no_forecast_periods-4) + np.arange(0,no_forecast_periods-4)\n",
    "            #print('ensemble no ',iens)\n",
    "            #        d_SIC_lead_time['ensemble'].iloc[ens_ind] = np.tile(iens,no_forecast_periods*len(init_times))\n",
    "            #Subset our sea ice extent by init_tim, ensemble no., and region\n",
    "            I_test = extent[itime,iens,:,region_select]\n",
    "            ##since we're doing 5-day means, our first and last 2 dates aren't included\n",
    "            ind_select = np.arange(2,no_forecast_periods-2) \n",
    "            min_range = ind_select - 2\n",
    "            max_range = ind_select + 2\n",
    "            ##Here's where we actually calculate that 5-day change in SIE\n",
    "            delta_extent = I_test[max_range] - I_test[min_range]\n",
    "            d_SIC_lead_time['d_SIC (V - I)'].iloc[save_ind] = delta_extent\n",
    "            ##Now, we get the dates that correspond to our valid date and number of lead days\n",
    "            forecast_dates = ind_select.astype('timedelta64[D]')\n",
    "            date_change = pd.Series(init_select).repeat(len(forecast_dates)) + forecast_dates\n",
    "            d_SIC_lead_time['V (valid date)'].iloc[save_ind] = pd.to_datetime(date_change.values)\n",
    "            d_SIC_lead_time['V_mon (valid date month)'].iloc[save_ind] = pd.to_datetime(date_change.values).month\n",
    "            d_SIC_lead_time['V_yr (valid date year)'].iloc[save_ind] = pd.to_datetime(date_change.values).year\n",
    "            ##We want to save lead time as a time delta, not a date\n",
    "            d_SIC_lead_time[\"lead time (days)\"].iloc[save_ind] = pd.to_timedelta(forecast_dates).days\n",
    "            ##This is just for saving files, because Python is 0-indexed but our ensemble no isn't\n",
    "            ens_no = iens + 1\n",
    "            ##Save info about our ensemble, region, and raw SIE data\n",
    "            d_SIC_lead_time['ensemble'].iloc[save_ind] = np.tile(ens_no,len(delta_extent))\n",
    "            d_SIC_lead_time['region'].iloc[save_ind] = np.tile(region_name,len(delta_extent))\n",
    "            d_SIC_lead_time['SIE'].iloc[save_ind] = I_test[ind_select]\n",
    "            #d_SIC_lead_time\n",
    "        if itime == 0:\n",
    "            df_ALL_init = d_SIC_lead_time\n",
    "        else:        \n",
    "            df_ALL_init = df_ALL_init.append(d_SIC_lead_time)\n",
    "        #    \n",
    "    if ireg == 0:\n",
    "        d_SIC_ALL_ens = df_ALL_init\n",
    "        #filename_full = filepath_save+'{model_name}_{model_type}_SIE_d_SIE_{d_days}day_change_lead_time_ALL_REGIONS_ALL_ENS.csv'.format(model_name=model_name,\n",
    "        #               model_type=model_type,d_days=no_day_change)\n",
    "        #d_SIC_ALL_ens.to_csv(filename_full)\n",
    "    else:\n",
    "        d_SIC_ALL_ens = d_SIC_ALL_ens.append(df_ALL_init)\n",
    "    #filename_full = filepath_save+'{model_name}_{model_type}_SIE_d_SIE_{d_days}day_change_lead_time_ALL_REGIONS_ALL_ENS.csv'.format(model_name=model_name,\n",
    "    #               model_type=model_type,d_days=no_day_change)\n",
    "    #d_SIC_ALL_ens.to_csv(filename_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_save = '/home/disk/sipn/mcmcgraw/data/VRILE/'\n",
    "filename_full = filepath_save+'{model_name}_{model_type}_SIE_d_SIE_{d_days}day_change_lead_time_ALL_REGIONS_ALL_ENS.csv'.format(model_name=model_name,\n",
    "                       model_type=model_type,d_days=no_day_change)\n",
    "d_SIC_ALL_ens.to_csv(filename_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2018"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
