{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>calculate_S2S_model_bias.ipynb</code>.  This notebook calculates bias (model - obs) in sea ice extent for each S2S model as a function of forecast month and region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from S2S_sea_ice_preprocess import load_model, create_aggregate_regions, create_model_climatology\n",
    "from S2S_sea_ice_preprocess import create_obs_climatology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>1) Load model netCDF files, combine with CTRL, and use common reforecast period. <br>\n",
    "if NCEP, use entire period </li>\n",
    "<li> 2) Add aggregate regions </li>\n",
    "<li> 3) Create climatology--model: calculate date of year for valid date, lead time in weeks.<br>\n",
    "<li> 4) Create observed climatology (static, using only common reforecast period) </li>\n",
    "<li> 5) Calculate bias at desired lead period (0 - <code>max_lead</code>) for each region, in each model, as a function of forecast month  \n",
    "    $$SIE_{bias} = \\overline{SIE_{model}(m,date)} - SIE_{obs}(m,date),$$\n",
    "    where the overline indicates averaging from lead days 0 - <code>max_lead</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names_ALL = ['ecmwf','ncep','ukmo','metreofr']\n",
    "obs_name = 'NSIDC_0079'\n",
    "COMMON_RF = True # we want to compare the reforecasts to obs over the same 15 year period\n",
    "MAX_LEAD = 1 #max lead in days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to look at all the models at once.  So we'll load each model, calculate the aggregate regions, get the ensemble mean, and create the climatology before combining everything into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  ecmwf\n",
      "<xarray.Dataset>\n",
      "Dimensions:       (ensemble: 10, fore_time: 46, init_time: 2080, nregions: 15)\n",
      "Coordinates:\n",
      "    region_names  (nregions) object dask.array<chunksize=(15,), meta=np.ndarray>\n",
      "  * fore_time     (fore_time) timedelta64[ns] 0 days 1 days ... 44 days 45 days\n",
      "  * ensemble      (ensemble) int32 0 1 2 3 4 5 6 7 8 9\n",
      "  * nregions      (nregions) int64 99 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      "  * init_time     (init_time) datetime64[ns] 1998-08-06 ... 2018-08-01\n",
      "Data variables:\n",
      "    Extent        (ensemble, init_time, fore_time, nregions) float64 dask.array<chunksize=(10, 1, 46, 15), meta=np.ndarray>\n",
      "loaded  ecmwf\n",
      "combined regions\n",
      "loading  ncep\n",
      "<xarray.Dataset>\n",
      "Dimensions:       (ensemble: 3, fore_time: 43, init_time: 4523, nregions: 15)\n",
      "Coordinates:\n",
      "    region_names  (nregions) object dask.array<chunksize=(15,), meta=np.ndarray>\n",
      "  * fore_time     (fore_time) timedelta64[ns] 1 days 2 days ... 42 days 43 days\n",
      "  * ensemble      (ensemble) int32 0 1 2\n",
      "  * nregions      (nregions) int64 99 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      "  * init_time     (init_time) datetime64[ns] 1999-01-01 ... 2010-12-31\n",
      "Data variables:\n",
      "    Extent        (ensemble, init_time, fore_time, nregions) float64 dask.array<chunksize=(3, 16, 43, 15), meta=np.ndarray>\n",
      "loaded  ncep\n",
      "combined regions\n",
      "loading  ukmo\n",
      "<xarray.Dataset>\n",
      "Dimensions:       (ensemble: 6, fore_time: 60, init_time: 1008, nregions: 15)\n",
      "Coordinates:\n",
      "    region_names  (nregions) object dask.array<chunksize=(15,), meta=np.ndarray>\n",
      "  * fore_time     (fore_time) timedelta64[ns] 0 days 1 days ... 58 days 59 days\n",
      "  * ensemble      (ensemble) int32 0 1 2 3 4 5\n",
      "  * nregions      (nregions) int64 99 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      "  * init_time     (init_time) datetime64[ns] 1995-01-01 ... 2015-12-25\n",
      "Data variables:\n",
      "    Extent        (ensemble, init_time, fore_time, nregions) float64 dask.array<chunksize=(6, 1, 60, 15), meta=np.ndarray>\n",
      "loaded  ukmo\n",
      "combined regions\n",
      "loading  metreofr\n",
      "<xarray.Dataset>\n",
      "Dimensions:       (ensemble: 14, fore_time: 60, init_time: 1056, nregions: 15)\n",
      "Coordinates:\n",
      "    region_names  (nregions) object dask.array<chunksize=(15,), meta=np.ndarray>\n",
      "  * fore_time     (fore_time) timedelta64[ns] 0 days 1 days ... 58 days 59 days\n",
      "  * ensemble      (ensemble) int32 0 1 2 3 4 5 6 7 8 9 10 11 12 13\n",
      "  * nregions      (nregions) int64 99 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      "  * init_time     (init_time) datetime64[ns] 1993-01-01 ... 2014-12-22\n",
      "Data variables:\n",
      "    Extent        (ensemble, init_time, fore_time, nregions) float64 dask.array<chunksize=(14, 1, 60, 15), meta=np.ndarray>\n",
      "loaded  metreofr\n",
      "combined regions\n"
     ]
    }
   ],
   "source": [
    "SIE_df_ALL = pd.DataFrame()\n",
    "SIE_df_weekly_ALL = pd.DataFrame()\n",
    "for model_name in model_names_ALL:\n",
    "    print('loading ',model_name)\n",
    "    # Load\n",
    "    SIE = load_model(model_name)\n",
    "    print('loaded ',model_name)\n",
    "    # Create aggregate regions\n",
    "    SIE = create_aggregate_regions(SIE)\n",
    "    print('combined regions')\n",
    "    # Take ensemble mean and get lead time in days\n",
    "    SIE_ens_mean = SIE.mean(dim='ensemble')\n",
    "    regions = SIE.region_names\n",
    "    lead_days = SIE.fore_time.dt.days\n",
    "    # Convert to dataframe, rename some columns, and get the date of the forecast by adding the fore_time to init_date\n",
    "    SIE_df = SIE_ens_mean.to_dataframe().reset_index()\n",
    "    SIE_df['valid date'] = SIE_df['init_time'] + SIE_df['fore_time']\n",
    "    SIE_df = SIE_df.rename(columns={'region_names':'region',\n",
    "                               'fore_time':'lead time (days)',\n",
    "                               'init_time':'init date',\n",
    "                               'Extent':'SIE'})\n",
    "    SIE_df = create_model_climatology(SIE_df,7)\n",
    "    SIE_df['model name'] = model_name\n",
    "    \n",
    "# Create climatology\n",
    "    SIE_df_ALL = SIE_df_ALL.append(SIE_df)\n",
    "    #SIE_df_weekly_ALL = SIE_df_weekly_ALL.append(SIE_df_weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening  <xarray.Dataset>\n",
      "Dimensions:       (nregions: 15, time: 11322)\n",
      "Coordinates:\n",
      "    region_names  (nregions) object dask.array<chunksize=(15,), meta=np.ndarray>\n",
      "  * nregions      (nregions) int64 99 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      "  * time          (time) datetime64[ns] 1989-01-01 1989-01-02 ... 2019-12-31\n",
      "Data variables:\n",
      "    Extent        (time, nregions) float64 dask.array<chunksize=(365, 15), meta=np.ndarray>\n",
      "obs loaded\n"
     ]
    }
   ],
   "source": [
    "obs_type = 'sipn_nc_yearly_agg'\n",
    "filepath = '/home/disk/sipn/nicway/data/obs/{model_name}/{model_type}/'.format(model_name=obs_name,\n",
    "                                                                              model_type=obs_type)\n",
    "obs_filenames = xr.open_mfdataset(filepath+'/*.nc',combine='by_coords')\n",
    "print('opening ',obs_filenames)\n",
    "obs_SIE = obs_filenames.Extent\n",
    "obs_regions = obs_filenames.nregions\n",
    "obs_region_names = obs_filenames['region_names'].values\n",
    "# Drop region names and re-add as a non-dask.array object.  This is stupid but oh well\n",
    "obs_SIE = obs_SIE.drop('region_names')\n",
    "obs_SIE[\"region_names\"] = (\"nregions\",obs_region_names)\n",
    "print('obs loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add aggregate regions to obs and convert obs to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database is locked')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "obs_SIE = create_aggregate_regions(obs_SIE)\n",
    "obs_SIE = obs_SIE.to_dataframe().reset_index()\n",
    "obs_SIE = obs_SIE.rename(columns={'Extent':'SIE','region_names':'region','time':'valid date'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate our observed climatology using either the full period or the common reforecast period only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common reforecast\n",
      "observed climatology created\n"
     ]
    }
   ],
   "source": [
    "if COMMON_RF == True:\n",
    "    obs_SIE = obs_SIE[pd.to_datetime(obs_SIE['valid date']).dt.year.isin(np.arange(1999,2015))]\n",
    "    obs_SIE = create_obs_climatology(obs_SIE)\n",
    "    time_str = 'COMMON_RF'\n",
    "    print('common reforecast')\n",
    "else:\n",
    "    time_str = 'FULL_PERIOD'\n",
    "    obs_SIE = create_obs_climatology(obs_SIE)\n",
    "    print('full period')\n",
    "print('observed climatology created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_SIE['model name'] = obs_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by model name, region, lead time (for model output only), and the forecast valid date, and subtract the observed SIE from the model prediction of SIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/mcmcgraw/anaconda3/envs/sea_ice_variability_S2S/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/disk/sipn/mcmcgraw/anaconda3/envs/sea_ice_variability_S2S/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "SIE_model_gb = SIE_df_ALL.groupby(['region','valid date','model name','lead time (days)'])['SIE','SIE clim','SIE anom'].mean()\n",
    "SIE_obs_gb = obs_SIE.groupby(['region','valid date'])['SIE','SIE clim','SIE anom'].mean()\n",
    "SIE_err = SIE_model_gb[['SIE','SIE clim','SIE anom']] - SIE_obs_gb[['SIE','SIE clim','SIE anom']]\n",
    "SIE_err_pct = SIE_err[['SIE','SIE clim','SIE anom']].divide(SIE_obs_gb[['SIE','SIE clim','SIE anom']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_err_pct = SIE_err_pct*100\n",
    "SIE_err[['SIE pct','SIE clim pct','SIE anom pct']] = SIE_err_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_err_rs = SIE_err.reset_index()\n",
    "SIE_err_rs['valid month'] = pd.to_datetime(SIE_err_rs['valid date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fname_save = '../DATA/RAW_ERRORS_all_S2S_models_OBS_{obs_name}_{time_str}.csv'.format(obs_name=obs_name,time_str=time_str)\n",
    "SIE_err_rs.to_csv(fname_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sea_ice_variability_S2S",
   "language": "python",
   "name": "sea_ice_variability_s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
