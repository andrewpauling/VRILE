{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>plot_RMSE_MAE_S2S_models_VRILE_counts_LINE_PLOTS.ipynb</code>.  This notebook plots VRILE count as a function of region, month, and lead time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>inputs:</b><br>\n",
    "<li>  model name (ecmwf,ukmo,ncep,metreofr) </li>\n",
    "<li>  seas_str [string for season; ALL if we want to do full year]</li>\n",
    "<li>  seas_sel [months of season; empty if we want to do full year] </li>\n",
    "<li>  vrile_thresh [threshhold at which VRILE is estimated </li>\n",
    "<li>  thresh_str [string for VRILE threshhold] </li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>1) Load model netCDF files, combine with CTRL, and use common reforecast period. <br>\n",
    "if NCEP, use entire period </li>\n",
    "<li> 2) Add aggregate regions </li>\n",
    "<li> 3) Create climatology--model: calculate date of year for valid date, lead time in weeks.<br>\n",
    "    Group by region, lead time, and valid date of year <br>\n",
    "    Average climatology based on day of year and lead time in weeks--use <code>transform</code> to create <code>SIE_clim</code>.<br> \n",
    "    Subtract <code>SIE_clim</code> from <code>SIE</code><br> </li>\n",
    "<li> 4) Create observed climatology </li>\n",
    "<li> 5) Calculate VRILE threshold based on <code>seas_sel</code> </li>\n",
    "<li> 6) Count number of VRILE days as a function of region, month, and lead week </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the netCDF files for our specific model from <code>/home/disk/sipn/nicway</code>.  We want the control runs too.  Then, select only the common reforecast period (1999-01-01 to 2014-12-31), and add the control run to the rest of the output. <br>\n",
    "NOTE: for NCEP, since the reforecast period is short (ends in 2011), we will just use the entire period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    # Paths for perturb and control runs\n",
    "    filepath = '/home/disk/sipn/nicway/data/model/{model_name}/reforecast/sipn_nc_agg/'.format(model_name=model_name)\n",
    "    filepath_ctrl = '/home/disk/sipn/nicway/data/model/{model_name}/reforecast.control/sipn_nc_agg/'.format(model_name=model_name)\n",
    "    # Open both with xarray\n",
    "    filenames = xr.open_mfdataset(filepath+'/*.nc',combine='by_coords')\n",
    "    filenames_ctrl = xr.open_mfdataset(filepath_ctrl+'/*.nc',combine='by_coords')\n",
    "    print(filenames)\n",
    "    # load SIE\n",
    "    SIE = filenames.Extent\n",
    "    SIE_ctrl = filenames_ctrl.Extent\n",
    "    # Add coordinate to ensemble dimension for SIE_ctrl so we can combine with SIE\n",
    "    SIE_ctrl.coords['ensemble'] = xr.DataArray([len(SIE.ensemble)],\n",
    "                                               dims='ensemble', coords={'ensemble':[len(SIE.ensemble)]})\n",
    "    # Use common reforecast period for all models EXCEPT NCEP\n",
    "    if model_name == 'ncep':\n",
    "        # Don't need to use a common reforecast but remove repeated indices\n",
    "        _,init_ind = np.unique(SIE['init_time'],return_index=True)\n",
    "        _,init_ind_c = np.unique(SIE_ctrl['init_time'],return_index=True)\n",
    "        SIE = SIE.isel(init_time=init_ind)\n",
    "        SIE_ctrl = SIE_ctrl.isel(init_time=init_ind_c)\n",
    "    elif model_name != 'ncep':\n",
    "        common_start = '1999-01-01'\n",
    "        common_end = '2014-12-31'\n",
    "        # Select only common reforecast period (full period for NCEP)\n",
    "        SIE = SIE.sel(init_time=slice(common_start,common_end))\n",
    "        SIE_ctrl = SIE_ctrl.sel(init_time=slice(common_start,common_end))\n",
    "        # Remove repeated indices in CTRL\n",
    "        _,init_ind_c = np.unique(SIE_ctrl['init_time'],return_index=True)\n",
    "        SIE_ctrl = SIE_ctrl.isel(init_time=init_ind_c)\n",
    "    # Concatenate the two\n",
    "    SIE = xr.concat([SIE,SIE_ctrl],dim='ensemble')\n",
    "    \n",
    "    return SIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a few aggregate regions from the NSIDC MASIE regions (more at: https://nsidc.org/data/masie/browse_regions) since some regions are so small. We're going to combine the following: <br>\n",
    "<li> Kara and Laptev Seas (<code>region_KL</code>)</li>\n",
    "<li> Barents, Kara and Laptev Seas (<code>region_BKL</code>)</li>\n",
    "<li> East Siberian, Beaufort, and Chukchi Seas (<code>region_EBC</code>)</li>\n",
    "<li> Atlantic (Baffin Bay and East Greenland Sea) (<code>region_ATL</code>)</li>\n",
    "<li> East Siberian, Beaufort, Chukchi, Laptev Seas (<code>region_EBCL</code>)</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregate_regions(SIE_data):\n",
    "    nregions = SIE_data['nregions']\n",
    "    region_names = SIE_data['region_names']\n",
    "    # Get corresponding indices for each of our aggregate regions\n",
    "    region_KL = nregions[region_names.isin(['Kara Sea','Laptev Sea'])]\n",
    "    region_BKL = nregions[region_names.isin(['Barents Sea','Kara Sea','Laptev Sea'])]\n",
    "    region_EBC = nregions[region_names.isin(['East Siberian Sea','Beaufort Sea','Chukchi Sea'])]\n",
    "    region_ATL = nregions[region_names.isin(['Baffin Bay','East Greenland Sea'])]\n",
    "    region_EBCL = nregions[region_names.isin(['East Siberian Sea','Beaufort Sea','Chukchi Sea','Laptev Sea'])]\n",
    "    # Select each aggregate region, add them together, and add the 'nregions' dimension back; concatenate all aggregates \n",
    "    SIE_agg = xr.concat([SIE_data.sel(nregions=region_KL).sum(dim='nregions').expand_dims(dim='nregions'),\n",
    "                  SIE_data.sel(nregions=region_BKL).sum(dim='nregions').expand_dims(dim='nregions'),\n",
    "                  SIE_data.sel(nregions=region_EBC).sum(dim='nregions').expand_dims(dim='nregions'),\n",
    "                  SIE_data.sel(nregions=region_ATL).sum(dim='nregions').expand_dims(dim='nregions'),\n",
    "                  SIE_data.sel(nregions=region_EBCL).sum(dim='nregions').expand_dims(dim='nregions')],dim='nregions')\n",
    "    # Add coordinates to nregions.  Start at 20 to make a clear separation from original NSIDC regions\n",
    "    SIE_agg = SIE_agg.assign_coords(nregions=[20,21,22,23,24])\n",
    "    # Add region names\n",
    "    region_names_extra = ['Kara-Laptev Sea','Barents-Kara-Laptev Sea','East Siberian-Beaufort-Chukchi Sea',\n",
    "                      'Atlantic','East Siberian-Beaufort-Chukchi-Laptev Sea']\n",
    "    SIE_agg[\"region_names\"] = (\"nregions\",region_names_extra)\n",
    "    #SIE\n",
    "    SIE_data = xr.concat([SIE_data,SIE_agg],dim='nregions')\n",
    "    return(SIE_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create climatology for model output based on region, day of year, and lead time.  Get month-day for valid dates (don't use dayofyear because of leap days).  Since our forecasts are not initialized every day, we will do two versions--one where we keep each lead time separate, and one where we group our lead time climatology based on week instead of day (which is more supported in the literature). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_climatology(SIE,week_length):\n",
    "    # Add valid date in %m-%d format\n",
    "    SIE['valid date of yr'] = pd.to_datetime(SIE['valid date']).dt.strftime('%m-%d')\n",
    "    # Determine lead time as a function of weeks instead of days\n",
    "    SIE_df_weekly = SIE.copy()\n",
    "    SIE_df_weekly['lead time (weeks)'] = SIE_df['lead time (days)'].values.astype('timedelta64[D]')/pd.Timedelta(week_length,'D')\n",
    "    SIE_df_weekly['lead time (weeks)'] = SIE_df_weekly['lead time (weeks)'].apply(np.floor)\n",
    "    # Group by region, lead time, and valid day of year. Use .transform('mean') so that our climatology has the \n",
    "    # same shape as the original input dataframe (so we can just subtract SIE_clim from SIE easily at the end)\n",
    "    SIE['SIE clim'] = SIE.groupby(['region','lead time (days)','valid date of yr'])['SIE'].transform('mean')\n",
    "    SIE_df_weekly['SIE clim'] = SIE_df_weekly.groupby(['region','lead time (weeks)','valid date of yr'])['SIE'].transform('mean')\n",
    "\n",
    "    SIE['SIE anom'] = SIE['SIE'] - SIE['SIE clim']\n",
    "    SIE_df_weekly['SIE anom'] = SIE_df_weekly['SIE'] - SIE_df_weekly['SIE clim']\n",
    "    return(SIE,SIE_df_weekly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create climatology for the observations.  This is easier, we just need to get the day of year (month-day) for each observation, take the mean, and then subtract the annual cycle from our full dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_obs_climatology(SIE):\n",
    "    # Add valid date in %m-%d format\n",
    "    SIE['valid day of year'] = pd.to_datetime(SIE['valid date']).dt.strftime('%m-%d')\n",
    "    # Group by region and day of year and take the mean. Use transform to make the output match the dataframe instead\n",
    "    # of creating a multi-index\n",
    "    SIE['SIE clim'] = SIE.groupby(['region','valid day of year'])['SIE'].transform('mean')\n",
    "    # And simply subtract SIE_clim from actual SIE\n",
    "    SIE['SIE anom'] = SIE['SIE'] - SIE['SIE clim']\n",
    "    return SIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate VRILE days from obs.  Determine $n$-day changes in SIE and anomalous SIE, and estimate the lower tail of the distribution based on <code>VRILE_thresh</code>.  For now, we'll assume we need a 5-day change in SIE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_VRILE_thresh(obs_SIE,plot_quant,vrile_thresh,nday_change,seas_sel,seas_str):\n",
    "    # Use shift to move SIE/SIE anom foreward and backward by nday_change days\n",
    "    nday_shift = np.floor(nday_change/2)\n",
    "    obs_SIE['SIE anom -n'] = obs_SIE.groupby(['region'])['SIE anom'].shift(-nday_shift)\n",
    "    obs_SIE['SIE anom +n'] = obs_SIE.groupby(['region'])['SIE anom'].shift(+nday_shift)\n",
    "    obs_SIE['SIE -n'] = obs_SIE.groupby(['region'])['SIE'].shift(-nday_shift)\n",
    "    obs_SIE['SIE +n'] = obs_SIE.groupby(['region'])['SIE'].shift(+nday_shift)\n",
    "    obs_SIE['d_SIE'] = obs_SIE['SIE -n'] - obs_SIE['SIE +n']\n",
    "    obs_SIE['d_SIE anom'] = obs_SIE['SIE anom -n'] - obs_SIE['SIE anom +n']\n",
    "    # \n",
    "    region_names = obs_SIE['region'].unique().tolist()\n",
    "    obs_SIE = obs_SIE.set_index('region')\n",
    "    # Trim to correct season based on seas_sel\n",
    "    obs_SIE_VRILE_only = pd.DataFrame()\n",
    "    for ireg in region_names:\n",
    "        SIE_ireg = obs_SIE.loc[ireg]\n",
    "        if seas_str == 'ALL':\n",
    "            SIE_ireg['p05'] = SIE_ireg[plot_quant].quantile(vrile_thresh)\n",
    "        else:\n",
    "            SIE_ireg['p05'] = SIE_ireg[SIE_ireg['valid date month'].isin(seas_sel)][plot_quant].quantile(vrile_thresh)\n",
    "        SIE_ivrile = SIE_ireg.where(SIE_ireg[plot_quant]<=SIE_ireg['p05']).dropna(how='all')\n",
    "        obs_SIE_VRILE_only = obs_SIE_VRILE_only.append(SIE_ivrile)\n",
    "\n",
    "    return obs_SIE_VRILE_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate raw error, mean absolute error, and RMSE.  These calculations will be a function of region and lead time.  See nice notebook for equations for RMSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_errors(model_SIE,obs_SIE):\n",
    "    model_SIE['lead days'] = model_SIE['lead time (days)'].dt.days\n",
    "    # Group by region, valid date, and lead time (for model)\n",
    "    SIE_obsx = obs_SIE.groupby(['region','valid date'])['SIE','SIE clim','SIE anom'].mean()\n",
    "    # First calculate raw model error (we'll also group by init time so we can save that for calculating other stuff)\n",
    "    SIE_model_raw = model_SIE.groupby(['region','valid date','lead days','init date'])['SIE','SIE clim','SIE anom'].mean()\n",
    "    SIE_raw_error = SIE_model_raw[['SIE','SIE anom']] - SIE_obsx[['SIE','SIE anom']]\n",
    "    SIE_raw_error = SIE_raw_error.dropna(how='all')\n",
    "    # Now, we'll do MAE and RMSE (we don't care about the date of initialization)\n",
    "    SIE_modelx = model_SIE.groupby(['region','valid date','lead days'])['SIE','SIE clim','SIE anom'].mean()\n",
    "    SIE_diff = SIE_modelx[['SIE','SIE anom']] - SIE_obsx[['SIE','SIE anom']]\n",
    "    # Square errors to get RMSE. get absolute value of errors for MAE\n",
    "    SIE_diff = SIE_diff.dropna(how='all')\n",
    "    SIE_diff = SIE_diff.rename(columns={'SIE':'SIE raw error','SIE anom':'SIE anom raw error'})\n",
    "    SIE_diff[['SIE sq error','SIE anom sq error']] = SIE_diff**2\n",
    "    # Now, average over all valid dates and take the square root. \n",
    "    SIE_errors = SIE_diff[['SIE sq error','SIE anom sq error']].mean(level=(0,2))**0.5\n",
    "    # Absolute value, then average over all valid dates to get the MAE\n",
    "    SIE_errors[['SIE MAE','SIE anom MAE']] = SIE_diff[['SIE raw error','SIE anom raw error']].abs().mean(level=(0,2))\n",
    "    SIE_errors = SIE_errors.rename(columns={'SIE sq error':'SIE RMSE','SIE anom sq error':'SIE anom RMSE'})\n",
    "    return(SIE_raw_error,SIE_errors)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ecmwf'\n",
    "seas_str = 'ALL'\n",
    "seas_sel = []\n",
    "obs_name = 'NSIDC_0079'\n",
    "WEEKLY = False\n",
    "vrile_thresh = 0.05\n",
    "thresh_str = '05'\n",
    "nday_change = 5 #number of days for VRILE calculation\n",
    "lead_day_min = 0\n",
    "lead_day_max = 7\n",
    "COMMON_REFORECAST = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model output for our desired model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:       (ensemble: 10, fore_time: 46, init_time: 2080, nregions: 15)\n",
      "Coordinates:\n",
      "    region_names  (nregions) object dask.array<chunksize=(15,), meta=np.ndarray>\n",
      "  * fore_time     (fore_time) timedelta64[ns] 0 days 1 days ... 44 days 45 days\n",
      "  * ensemble      (ensemble) int32 0 1 2 3 4 5 6 7 8 9\n",
      "  * nregions      (nregions) int64 99 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      "  * init_time     (init_time) datetime64[ns] 1998-08-06 ... 2018-08-01\n",
      "Data variables:\n",
      "    Extent        (ensemble, init_time, fore_time, nregions) float64 dask.array<chunksize=(10, 1, 46, 15), meta=np.ndarray>\n",
      "loaded  ecmwf\n"
     ]
    }
   ],
   "source": [
    "SIE = load_model(model_name)\n",
    "print('loaded ',model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create aggregate regions that combine some of the NSIDC-MASIE regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined regions\n"
     ]
    }
   ],
   "source": [
    "SIE = create_aggregate_regions(SIE)\n",
    "print('combined regions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take the ensemble mean and get lead time in days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_ens_mean = SIE.mean(dim='ensemble')\n",
    "regions = SIE.region_names\n",
    "lead_days = SIE.fore_time.dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to dataframe because I like Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_df = SIE_ens_mean.to_dataframe().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the date for forecasts by adding the <code>fore_time</code> to <code>init_time</code>. Rename some columns to make life easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_df['valid date'] = SIE_df['init_time'] + SIE_df['fore_time']\n",
    "SIE_df = SIE_df.rename(columns={'region_names':'region',\n",
    "                           'fore_time':'lead time (days)',\n",
    "                           'init_time':'init date',\n",
    "                           'Extent':'SIE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want only the common reforecast period (<code>COMMON_REFORECAST == True</code>), trim now to 1999-2014 except for <code>NCEP</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (COMMON_REFORECAST == True) & (model_name != 'ncep'):\n",
    "    SIE_df = SIE_df[pd.to_datetime(SIE_df['init date']).dt.year.isin(np.arange(1999,2015))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create climatology for model output.  Decide how long we want weeks to be for weekly climatology (default is 7 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model climatology created\n"
     ]
    }
   ],
   "source": [
    "week_length = 7\n",
    "SIE_df,SIE_df_weekly = create_model_climatology(SIE_df,7)\n",
    "print('model climatology created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load observations.  NSIDC_0079 is NASA Bootstrap, NSIDC_0081 is NASA team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening  <xarray.Dataset>\n",
      "Dimensions:       (nregions: 15, time: 11322)\n",
      "Coordinates:\n",
      "    region_names  (nregions) object dask.array<chunksize=(15,), meta=np.ndarray>\n",
      "  * nregions      (nregions) int64 99 2 3 4 5 6 7 8 9 10 11 12 13 14 15\n",
      "  * time          (time) datetime64[ns] 1989-01-01 1989-01-02 ... 2019-12-31\n",
      "Data variables:\n",
      "    Extent        (time, nregions) float64 dask.array<chunksize=(365, 15), meta=np.ndarray>\n",
      "obs loaded\n"
     ]
    }
   ],
   "source": [
    "obs_type = 'sipn_nc_yearly_agg'\n",
    "filepath = '/home/disk/sipn/nicway/data/obs/{model_name}/{model_type}/'.format(model_name=obs_name,\n",
    "                                                                              model_type=obs_type)\n",
    "obs_filenames = xr.open_mfdataset(filepath+'/*.nc',combine='by_coords')\n",
    "print('opening ',obs_filenames)\n",
    "obs_SIE = obs_filenames.Extent\n",
    "obs_regions = obs_filenames.nregions\n",
    "obs_region_names = obs_filenames['region_names'].values\n",
    "# Drop region names and re-add as a non-dask.array object.  This is stupid but oh well\n",
    "obs_SIE = obs_SIE.drop('region_names')\n",
    "obs_SIE[\"region_names\"] = (\"nregions\",obs_region_names)\n",
    "print('obs loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add aggregate regions to obs and convert obs to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_SIE = create_aggregate_regions(obs_SIE)\n",
    "obs_SIE = obs_SIE.to_dataframe().reset_index()\n",
    "obs_SIE = obs_SIE.rename(columns={'Extent':'SIE','region_names':'region','time':'valid date'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again trim to common reforecast if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMMON_REFORECAST == True:\n",
    "    obs_SIE = obs_SIE[pd.to_datetime(obs_SIE['valid date']).dt.year.isin(np.arange(1999,2015))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate our observed climatology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observed climatology created\n"
     ]
    }
   ],
   "source": [
    "obs_SIE = create_obs_climatology(obs_SIE)\n",
    "print('observed climatology created')\n",
    "obs_SIE['valid date month'] = pd.to_datetime(obs_SIE['valid date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "obspath_save = '/home/disk/sipn/mcmcgraw/McGraw_etal_2020/code/make_it_nice/data/OBS_{obs_name}_all_regions_climatology_created'.format(obs_name=obs_name)\n",
    "if COMMON_REFORECAST == True:\n",
    "    obspath_save = obspath_save+'_COMMON_REFORECAST.csv'\n",
    "else:\n",
    "    obspath_save = obspath_save+'_ALL_YEARS.csv'\n",
    "obs_SIE.to_csv(obspath_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get observed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/mcmcgraw/anaconda3/envs/sea_ice_variability_S2S/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "obs_SIE_VRILE_only = calc_VRILE_thresh(obs_SIE,'d_SIE',vrile_thresh,nday_change,seas_sel,seas_str)\n",
    "obs_SIE_anom_VRILE_only = calc_VRILE_thresh(obs_SIE,'d_SIE anom',vrile_thresh,nday_change,seas_sel,seas_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get model VRILE days as a function of lead week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIE_df_weekly['valid date month'] = pd.to_datetime(SIE_df_weekly['valid date']).dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/disk/sipn/mcmcgraw/anaconda3/envs/sea_ice_variability_S2S/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n",
      "/home/disk/sipn/mcmcgraw/anaconda3/envs/sea_ice_variability_S2S/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "SIE_df_weekly_gb = SIE_df_weekly.groupby(['lead time (weeks)','region',\n",
    "                       'valid date','init date'])['SIE','SIE clim','SIE anom','valid date month'].mean()\n",
    "SIE_model_VRILE = pd.DataFrame()\n",
    "SIE_anom_model_VRILE = pd.DataFrame()\n",
    "weeks_list = SIE_df_weekly_gb.index.get_level_values('lead time (weeks)').unique().tolist()\n",
    "for iweek in weeks_list:\n",
    "    i_SIE = calc_VRILE_thresh(SIE_df_weekly_gb.xs(iweek).reset_index(),'d_SIE',\n",
    "                                         vrile_thresh,nday_change,seas_sel,seas_str)\n",
    "    i_SIE['lead weeks'] = iweek\n",
    "    i_SIE_anom = calc_VRILE_thresh(SIE_df_weekly_gb.xs(iweek).reset_index(),'d_SIE anom',\n",
    "                                         vrile_thresh,nday_change,seas_sel,seas_str)\n",
    "    i_SIE_anom['lead weeks'] = iweek\n",
    "    SIE_model_VRILE = SIE_model_VRILE.append(i_SIE)\n",
    "    SIE_anom_model_VRILE = SIE_anom_model_VRILE.append(i_SIE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files saved\n"
     ]
    }
   ],
   "source": [
    "clim_freq_str = 'WEEKLY'\n",
    "fdir = '/home/disk/sipn/mcmcgraw/McGraw_etal_2020/code/make_it_nice/data/{model_name}/'.format(model_name=model_name)\n",
    "if COMMON_REFORECAST == True:\n",
    "    fdir = fdir+'COMMON_REFORECAST/'\n",
    "    \n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "fname_save_raw = fdir+'VRILE_count_SIE_{model_name}_months{seas_str}_VRILE{thresh_str}_model_clim_freq_{clim_freq_str}.csv'.format(model_name=model_name,\n",
    "                                             seas_str=seas_str,thresh_str=thresh_str,clim_freq_str=clim_freq_str)\n",
    "fname_save_RMSE = fdir+'VRILE_count_SIE_anom_{model_name}_months{seas_str}_VRILE{thresh_str}_model_clim_freq_{clim_freq_str}.csv'.format(model_name=model_name,\n",
    "                                             seas_str=seas_str,thresh_str=thresh_str,clim_freq_str=clim_freq_str)\n",
    "fname_save_obs = fdir+'VRILE_count_SIE_obs_months{seas_str}_VRILE{thresh_str}_model_clim_freq_{clim_freq_str}.csv'.format(\n",
    "                                             seas_str=seas_str,thresh_str=thresh_str,clim_freq_str=clim_freq_str)\n",
    "fname_save_obs_anom = fdir+'VRILE_count_SIE_anom_obs_months{seas_str}_VRILE{thresh_str}_model_clim_freq_{clim_freq_str}.csv'.format(\n",
    "                                             seas_str=seas_str,thresh_str=thresh_str,clim_freq_str=clim_freq_str)\n",
    "SIE_model_VRILE.to_csv(fname_save_raw)\n",
    "SIE_anom_model_VRILE.to_csv(fname_save_RMSE)\n",
    "#\n",
    "obs_SIE_VRILE_only.to_csv(fname_save_obs)\n",
    "obs_SIE_anom_VRILE_only.to_csv(fname_save_obs_anom)\n",
    "print('files saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/disk/sipn/mcmcgraw/McGraw_etal_2020/code/make_it_nice/data/ecmwf/COMMON_REFORECAST/VRILE_count_SIE_ecmwf_monthsALL_VRILE05_model_clim_freq_WEEKLY.csv'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname_save_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sea_ice_variability_S2S",
   "language": "python",
   "name": "sea_ice_variability_s2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
